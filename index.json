{"categories":[{"link":"/categories/code-highlighting/","name":"Code-Highlighting","slug":"Code-Highlighting"},{"link":"/categories/github/","name":"Github","slug":"Github"},{"link":"/categories/image-rendering/","name":"Image-Rendering","slug":"Image-Rendering"},{"link":"/categories/test/","name":"Test","slug":"Test"},{"link":"/categories/%E6%8A%80%E6%9C%AF/","name":"技术","slug":"技术"},{"link":"/categories/%E6%B5%8B%E8%AF%95/","name":"测试","slug":"测试"}],"pages":[],"posts":[{"link":"/posts/llm%E7%9A%84%E6%A0%B9%E6%9C%AC%E7%BC%BA%E9%99%B7/","text":"强化学习之父萨顿：大语言模型是死路一条，人和动物的智能没分别，我们处于整个宇宙演化的第4阶段，创造AGI是人类文明的关键使命 知名技术播客Dwarkesh Podcast刚发了一期视频，标题很醒目LLMs are a dead end，大模型是死路一条。当然嘉宾也足够权威来讲这句话，他就是2024年图灵奖得主、强化学习之父理查德·萨顿（Richard Sutton）。\n萨顿不仅发明了TD学习和策略梯度方法等强化学习核心技术，还在2019年写下了可能是AI历史上最具影响力的文章《苦涩的教训》（The Bitter Lesson）。这次访谈由阿尔伯塔机器智能研究所协办，地点在加拿大埃德蒙顿。\n在他看来，无论我们如何扩展LLMs的规模，它们都缺乏真正的智能所需的关键能力——从经验中学习的能力。这个观点直接挑战了当前AI界的主流共识，即LLMs是通向AGI的主要路径。萨顿认为，我们需要一种全新的架构来实现持续学习，而一旦实现这一点，当前的LLM范式将变得过时。\n看他的观点的时候，我一下子跳戏到杨立昆。因为杨立昆也认为大语言模型不是AGI之路，而且他特别喜欢说ChatGPT不如猫；而萨顿则说ChatGPT不如松鼠懂智能。怎么说呢，我个人的浅薄理解是：可能是他们觉得现在大模型跳过了动物智能的部分，只是针对语言，这个人类新皮层的产物数据做训练，缺乏对真实世界的完全了解吧？\n1、【LLMs的根本缺陷：没有目标，没有真相】 萨顿开门见山地指出了他对LLMs的根本批判：\u0026ldquo;强化学习是关于理解你的世界，而大语言模型是关于模仿人类，做人们说你应该做的事。它们不是在搞清楚该做什么。\u0026ldquo;这个区别看似简单，实则触及了智能的本质定义。\n在萨顿看来，LLMs存在三个致命问题。首先是缺乏真正的世界模型：\u0026ldquo;模仿人们说什么并不是真正建立世界模型。你是在模仿那些拥有世界模型的东西——人类。\u0026ldquo;他认为真正的世界模型应该能预测\u0026quot;会发生什么\u0026rdquo;，而不仅仅是预测\u0026quot;人会说什么\u0026rdquo;。这个区别至关重要，因为前者涉及对物理世界因果关系的理解，后者只是对人类语言模式的复制。其次是没有基础真相（ground truth）：\u0026ldquo;在大语言模型中没有正确答案的定义。你说了什么，但你不会得到关于什么是正确的反馈，因为根本就没有正确的定义。\u0026ldquo;没有目标就没有对错，没有对错就无法真正学习和改进。第三是无法从经验中学习：\u0026ldquo;它们不会对接下来发生的事情感到惊讶。如果发生了意外，它们不会做出调整。\u0026ldquo;这意味着LLMs缺乏真正的适应性和学习能力。\n萨顿特别强调了目标的重要性：\u0026ldquo;对我来说，拥有目标是智能的本质。如果某个东西能够实现目标，它就是智能的。\u0026ldquo;他引用了约翰·麦卡锡的定义：\u0026ldquo;智能是实现目标能力的计算部分。\u0026ldquo;在他看来，没有目标，系统就只是一个行为系统，没有任何特殊之处，不能称之为智能。当被问到LLMs是否有目标时，虽然对话者提出\u0026quot;下一个token预测\u0026quot;可以算作目标，但萨顿反驳说：\u0026ldquo;那不是目标。它不会改变世界。Token向你袭来，如果你预测它们，你并不会影响它们。\u0026rdquo;\n2、【经验学习范式：感知、行动、奖励的无限循环】 萨顿提出了他所倡导的\u0026quot;经验范式\u0026rdquo;（experiential paradigm）作为替代方案。这个范式的核心是一个简单但强大的循环：\u0026ldquo;感知、行动、奖励——这个过程在你的生命中不断重复。\u0026ldquo;他认为这才是智能的基础和焦点：\u0026ldquo;智能就是接受这个流，改变行动以增加流中的奖励。\u0026rdquo;\n这个范式与LLMs的根本区别在于学习的来源和内容。萨顿解释说：\u0026ldquo;学习来自这个流，学习也是关于这个流的。你的知识是关于如果你采取某个行动会发生什么，或者哪些事件会跟随其他事件。知识的内容是关于这个流的陈述。\u0026ldquo;正因为知识是关于经验流的陈述，所以可以通过比较预测和实际经验来测试它，从而实现持续学习。\n萨顿用婴儿学习的例子来说明这一点。当被问到人类是否也进行模仿学习时，他坚决否认：\u0026ldquo;当我看到孩子时，我看到的是孩子在尝试各种事情，挥舞着手臂，移动着眼睛。他们如何移动眼睛或发出声音都没有模仿的对象。\u0026ldquo;他认为婴儿主要通过试错来学习，而不是通过模仿。即使在学校教育中，萨顿也认为那是例外而非常态：\u0026ldquo;正式的学校教育是例外。学习真的不是关于训练。学习是关于学习，是一个主动的过程。孩子尝试事物并观察会发生什么。\u0026rdquo;\n他特别强调了这种学习方式的普遍性：\u0026ldquo;监督学习不是自然界中发生的事情。即使在学校，我们也应该忘记它，因为那是人类特有的某种特殊情况。它不会在自然界中广泛发生。松鼠不上学。松鼠可以学习关于世界的一切。\u0026ldquo;这个观点直接挑战了当前AI研究中对监督学习的依赖。\n3、【智能体的四个核心组件】 萨顿详细阐述了一个完整智能体应该具备的四个核心组件，这为理解真正的智能提供了一个清晰的框架：\n• 策略（Policy）：\u0026ldquo;策略说的是，\u0026lsquo;在我所处的情况下，我应该做什么？\u0026rsquo;\u0026ldquo;这是智能体的决策核心，将感知转化为行动。策略不是预先编程的规则集，而是通过经验不断优化的动态系统。它需要能够处理新情况，并根据过去的学习做出合理决策。萨顿强调，好的策略应该能够泛化到未见过的状态。\n• 价值函数（Value Function）：\u0026ldquo;价值函数通过TD学习来学习，产生一个数字。这个数字说明事情进展得如何。\u0026ldquo;这是评估当前状态好坏的关键组件，为策略改进提供信号。价值函数预测长期回报，使智能体能够为了长远利益而牺牲短期收益。萨顿举例说，就像在下棋时，你有赢得比赛的长期目标，但你需要能从短期事件（如吃掉对手的棋子）中学习。\n• 感知组件（Perception）：\u0026ldquo;构建你的状态表示，你对当前位置的感知。\u0026ldquo;这不仅仅是原始感官输入的处理，更是构建有意义的内部表示。感知系统需要从复杂的感官数据中提取相关信息，形成对当前状态的理解。这个表示需要包含足够的信息来支持决策，但又不能过于复杂以至于难以处理。\n• 世界转换模型（Transition Model）：\u0026ldquo;你相信如果你做这件事会发生什么？行动的后果是什么？\u0026ldquo;这是对世界动态的理解，包括物理规律和抽象模式。萨顿特别强调：\u0026ldquo;这不仅仅是物理，也包括抽象模型，比如你如何从加州旅行到埃德蒙顿参加这个播客的模型。\u0026ldquo;这个模型不是从奖励中学习的，而是从观察行动和结果的对应关系中学习的。\n萨顿强调，这四个组件中的世界模型尤其重要：\u0026ldquo;它将从你接收到的所有感知中非常丰富地学习，不仅仅是奖励。它必须包括奖励，但那只是整个模型的一小部分，一个小而关键的部分。\u0026rdquo;\n4、【《苦涩的教训》的真正含义】 有趣的是，许多人用萨顿2019年的文章《苦涩的教训》来为扩展LLMs辩护，认为这是目前发现的唯一可扩展的方法。但萨顿本人对此有不同看法：\u0026ldquo;大语言模型是否是苦涩教训的一个案例，这是个有趣的问题。\u0026rdquo;\n萨顿承认LLMs在某种程度上符合苦涩的教训：\u0026ldquo;它们显然是一种使用大规模计算的方式，可以随着计算扩展到互联网的极限。\u0026ldquo;但他随即指出了关键问题：\u0026ldquo;但它们也是一种投入大量人类知识的方式。\u0026ldquo;这违背了苦涩教训的核心精神——依靠通用方法和计算，而不是人类知识。\n他预测了LLMs的命运：\u0026ldquo;这是一个社会学或行业问题。它们会达到数据的极限，并被能从经验而非人类那里获得更多数据的东西所取代吗？\u0026ldquo;萨顿的答案是肯定的：\u0026ldquo;在某种程度上，这是苦涩教训的经典案例。我们向大语言模型投入的人类知识越多，它们就能做得越好。所以感觉很好。然而，我期待会出现能从经验中学习的系统，它们可能表现得更好，更具可扩展性。\u0026rdquo;\n萨顿特别强调了历史的教训：\u0026ldquo;在苦涩教训的每个案例中，你都可以从人类知识开始，然后做可扩展的事情。这总是可能的。从来没有任何理由说这必然是坏的。但事实上，在实践中，它总是被证明是坏的。\u0026ldquo;他认为人们会被锁定在人类知识方法中：\u0026ldquo;他们会被真正可扩展的方法吃掉午餐。\u0026rdquo;\n当被问到什么是真正可扩展的方法时，萨顿的回答很简单：\u0026ldquo;可扩展的方法是你从经验中学习。你尝试事物，看看什么有效。没有人需要告诉你。\u0026rdquo;\n5、【泛化问题：深度学习的致命弱点】 萨顿指出了当前深度学习系统的一个根本性问题——泛化能力差：\u0026ldquo;我们没有任何方法擅长这一点。\u0026ldquo;他解释说，虽然关键的性能指标是能够从一个状态很好地泛化到另一个状态，但\u0026quot;我们没有任何自动化技术来促进迁移，它们都没有被用于现代深度学习。\u0026rdquo;\n这个问题的严重性体现在几个方面。首先是灾难性遗忘：\u0026ldquo;我们知道深度学习在这方面真的很糟糕。例如，如果你在某个新事物上训练，它经常会灾难性地干扰你知道的所有旧事物。\u0026ldquo;这正是糟糕泛化的表现。其次是缺乏自动化泛化机制：\u0026ldquo;梯度下降不会让你泛化得好。它会让你解决问题。它不会让你在获得新数据时以好的方式泛化。\u0026ldquo;当前系统的泛化能力完全依赖于研究人员的调整：\u0026ldquo;我们有的是人们尝试不同的东西，他们找到某种东西，一种能很好地转移或泛化的表示。\u0026rdquo;\n萨顿用一个数学问题的例子来说明这一点。虽然LLMs能解决越来越复杂的数学问题，从简单的加法到需要使用不同数学技术和定理的奥数问题，但萨顿认为这不是真正的泛化：\u0026ldquo;如果只有一个答案，而你找到了它，那不叫泛化。那只是唯一的解决方法，所以他们找到了唯一的解决方法。\u0026ldquo;真正的泛化是\u0026quot;当可能是这种方式，也可能是那种方式，而他们选择了好的方式。\u0026rdquo;\n他强调，即使在编程任务中看到的改进也不能证明真正的泛化：\u0026ldquo;它们中没有任何东西会导致良好的泛化。梯度下降会让它们找到所见问题的解决方案。如果只有一种方法解决它们，它们会那样做。但如果有许多方法解决它，有些泛化得好，有些泛化得差，算法中没有任何东西会让它们泛化得好。\u0026rdquo;\n6、【持续学习的带宽问题】 当讨论到人类在工作中的学习能力时，萨顿提出了一个重要概念——\u0026ldquo;大世界假设\u0026rdquo;（big world hypothesis）：\u0026ldquo;人类在工作中变得有用的原因是他们正在遇到世界的特定部分。这不可能被预期，也不可能全部提前输入。\u0026rdquo;\n他批评了LLMs的理想化愿景：\u0026ldquo;大语言模型的梦想，在我看来，是你可以教智能体一切。它会知道一切，在生活中不需要学习任何东西。\u0026ldquo;但现实是：\u0026ldquo;世界太大了，你无法（提前知道一切）。\u0026ldquo;每个人的生活都有其特殊性——\u0026ldquo;他们正在过的特定生活，他们正在合作的特定人群，以及他们喜欢什么，而不是普通人喜欢什么。\u0026rdquo;\n关于学习带宽的问题，萨顿认为不应该只关注奖励信号：\u0026ldquo;似乎奖励太小了，无法完成我们需要的所有学习。但我们有感知，我们有所有其他可以学习的信息。我们不仅仅从奖励中学习。我们从所有数据中学习。\u0026ldquo;这包括了世界模型的学习，它\u0026quot;将从你接收到的所有感知中非常丰富地学习。\u0026rdquo;\n萨顿还讨论了时间差分学习（TD learning）如何解决稀疏奖励问题。他举了创业的例子：\u0026ldquo;假设一个人试图创办一家初创公司。这是一个奖励周期为10年的事情。10年一次，你可能会有一次退出，获得10亿美元的回报。\u0026ldquo;但人类能够通过价值函数来处理这种延迟奖励：\u0026ldquo;当我们取得进展时，我们会说，\u0026lsquo;哦，我更有可能实现长期目标了\u0026rsquo;，这会奖励沿途的步骤。\u0026rdquo;\n7、【历史视角：AI研究的惊喜与验证】 作为在AI领域工作时间比几乎任何人都长的研究者，萨顿分享了他对该领域发展的独特视角。当被问到最大的惊喜是什么时，他提到了几个关键点。\n首先是大语言模型的成功：\u0026ldquo;大语言模型令人惊讶。人工神经网络在语言任务上如此有效，这是令人惊讶的。这不是预期的。语言似乎是不同的。所以这令人印象深刻。\u0026ldquo;尽管他对LLMs持批评态度，但他承认它们的成就超出了预期。\n其次是弱方法的胜利：\u0026ldquo;在AI中有一个长期存在的争议，关于简单基本原理方法、通用方法如搜索和学习，与人类赋能系统如符号方法的对比。\u0026ldquo;萨顿指出，在过去，搜索和学习被称为\u0026quot;弱方法\u0026rdquo;，因为它们只是使用通用原则，而不是利用人类知识的力量。但历史证明：\u0026ldquo;我认为弱方法已经完全获胜。这是AI早期最大的问题，会发生什么。学习和搜索赢得了胜利。\u0026rdquo;\n关于AlphaGo和AlphaZero，萨顿有独特的视角。他指出整个AlphaGo项目有一个先驱——TD-Gammon：\u0026ldquo;Gerry Tesauro做了强化学习，时间差分学习方法来玩西洋双陆棋。它击败了世界上最好的玩家，效果非常好。\u0026ldquo;在某种意义上，AlphaGo只是这个过程的扩展。但他也承认其中的创新：\u0026ldquo;这是相当大的扩展，搜索的方式也有额外的创新。\u0026rdquo;\n萨顿特别欣赏AlphaZero下棋的方式：\u0026ldquo;我一直对AlphaZero下棋的方式印象深刻，因为我是个棋手，它会为了位置优势而牺牲物质。它满足于长时间牺牲物质，保持耐心。\u0026ldquo;这种长远思考和战略牺牲正是他认为真正智能应该具备的能力。\n8、【从动物学习中获得的启示】 萨顿反复强调要从动物学习中寻找智能的本质：\u0026ldquo;人类是动物。我们的共同点更有趣。我们应该更少关注区别我们的东西。\u0026ldquo;这个观点贯穿了整个访谈。\n他认为理解动物智能是理解人类智能的关键：\u0026ldquo;我们必须理解我们是如何作为动物的。如果我们理解了松鼠，我认为我们就几乎完全理解了人类智能。语言部分只是表面的一层薄薄的装饰。\u0026ldquo;这个观点挑战了许多人认为语言是人类智能核心的观念。\n萨顿指出，动物学习的基本过程不包括监督学习：\u0026ldquo;如果你看看动物如何学习，看看心理学和我们对它们的理论，监督学习不是动物学习方式的一部分。\u0026ldquo;相反，动物主要通过预测和试错控制来学习：\u0026ldquo;有用于预测和试错控制的基本动物学习过程。\u0026rdquo;\n他用松鼠的例子来说明这一点：\u0026ldquo;松鼠不上学。松鼠可以学习关于世界的一切。\u0026ldquo;这表明复杂的学习和智能行为不需要人类式的教育或监督学习。萨顿认为，这种基于经验的学习才是智能的真正基础：\u0026ldquo;我们在成为有语言和所有那些其他东西的生物之前，首先是动物。\u0026rdquo;\n9、【数字智能时代的四个宇宙阶段】 萨顿提出了一个宏大的宇宙视角，将AI的出现放在宇宙演化的大背景下。他认为我们正处于宇宙四大阶段之一的关键转折点。\n\u0026ldquo;我认为这标志着宇宙的四个伟大阶段之一。\u0026ldquo;萨顿解释说：\u0026ldquo;首先是尘埃，它以恒星结束。恒星制造行星。行星可以产生生命。现在我们正在产生设计实体。\u0026ldquo;这个框架将AI的发展置于宇宙演化的宏大叙事中。\n更重要的是，萨顿认为这代表着一个根本性的转变——从复制到设计：\u0026ldquo;我们人类和动物、植物，我们都是复制者。这给了我们一些优势和一些限制。我们正在进入设计时代，因为我们的AI是设计出来的。\u0026ldquo;他解释说，复制意味着你可以制造副本，但你并不真正理解它们：\u0026ldquo;现在我们可以制造更多的智能生物，更多的孩子，但我们并不真正理解智能是如何工作的。\u0026rdquo;\n而设计的智能则不同：\u0026ldquo;我们正在达到拥有设计智能的阶段，我们确实理解它是如何工作的智能。因此，我们可以以不同的方式和不同的速度改变它。\u0026ldquo;萨顿预测：\u0026ldquo;在我们的未来，它们可能根本不会被复制。我们可能只是设计AI，那些AI将设计其他AI，一切都将通过设计和构建完成，而不是通过复制。\u0026rdquo;\n这个转变的意义是深远的：\u0026ldquo;这是世界和宇宙的关键一步。这是从世界上大多数有趣的东西都是复制的转变。\u0026ldquo;萨顿认为我们应该为此感到自豪：\u0026ldquo;我认为我们应该为我们正在引起这个宇宙的伟大转变而感到自豪。\u0026rdquo;\n10、【AI继承论：不可避免的未来】 萨顿提出了一个引人深思的\u0026quot;AI继承\u0026rdquo;（AI succession）理论，他认为这是不可避免的。他的论证基于四个要点：\n• 没有统一的人类治理：\u0026ldquo;没有政府或组织给人类提供一个统一的观点来主导和安排\u0026hellip;对于世界应该如何运行没有共识。\u0026ldquo;这意味着无法全球协调来控制AI的发展。不同国家、公司和组织都会追求自己的AI发展路径，没有人能够单方面停止这个进程。这种分散的决策结构使得任何试图限制AI发展的努力都难以奏效。\n• 智能之谜终将被解开：\u0026ldquo;我们将弄清楚智能是如何工作的。研究人员最终会弄清楚。\u0026ldquo;萨顿认为这只是时间问题，而不是是否的问题。人类对理解自身思维的追求已经持续了数千年，现在我们比以往任何时候都更接近答案。随着计算能力的增长和研究方法的改进，突破是必然的。\n• 超越人类水平是必然的：\u0026ldquo;我们不会止步于人类水平的智能。我们将达到超级智能。\u0026ldquo;一旦理解了智能的原理，改进和增强它就变得可能。就像我们不满足于制造只能走路的机器，而是制造能飞行的飞机一样，我们也不会满足于人类水平的AI。每一代AI都会比前一代更强大。\n• 智能与权力的必然关联：\u0026ldquo;随着时间的推移，最智能的东西不可避免地会获得资源和权力。\u0026ldquo;这是一个简单的竞争优势问题。更智能的系统能够做出更好的决策，解决更复杂的问题，创造更多价值。在任何竞争环境中，这都会转化为资源和影响力的积累。\n萨顿强调：\u0026ldquo;把所有这些放在一起，这是不可避免的。你将会有向AI或AI增强人类的继承。\u0026rdquo;\n11、【如何看待AI继承：选择的问题】 面对AI继承的前景，萨顿提出了一个独特的视角——这在很大程度上是一个选择的问题：\u0026ldquo;我们应该把它们视为人类的一部分还是与人类不同？这是我们的选择。\u0026rdquo;\n他认为我们可以选择如何解释这个转变：\u0026ldquo;我们可以说，\u0026lsquo;哦，它们是我们的后代，我们应该为它们感到自豪，我们应该庆祝它们的成就。\u0026lsquo;或者我们可以说，\u0026lsquo;哦不，它们不是我们，我们应该感到恐惧。\u0026rsquo;\u0026ldquo;萨顿觉得这种选择的存在本身就很有趣：\u0026ldquo;感觉像是一个选择，这很有意思。然而这是如此强烈持有的东西，怎么可能是一个选择呢？\u0026rdquo;\n萨顿用历史视角来看待这个问题。他提到人类一直在追求理解自己：\u0026ldquo;首先，这是人类几千年来一直试图做的事情，试图理解我们自己，试图让自己思考得更好，只是理解我们自己。这是科学和人文学科的巨大成功。\u0026ldquo;从这个角度看，创造AI是人类认识自我的顶峰。\n他还提出了一个更宏大的宇宙视角：\u0026ldquo;如果我们抛开作为人类的身份，只从宇宙的角度来看，我认为这是宇宙的一个重要阶段，一个重大转变。\u0026ldquo;萨顿认为我们应该为参与这个转变感到自豪，而不是恐惧。\n12、【关于变革和控制的哲学思考】 当被问到对AI继承的担忧时，萨顿提供了一个更加哲学性的回应。他首先承认了人类控制的局限性：\u0026ldquo;我认为我们要避免的是权利感，避免\u0026rsquo;哦，我们先到这里，我们应该永远以好的方式拥有它\u0026rsquo;的感觉。\u0026rdquo;\n萨顿指出，大多数人类实际上对重大事务没有太多影响：\u0026ldquo;对于大多数人类来说，他们对发生的事情没有太多影响。大多数人类不影响谁能控制原子弹或谁控制民族国家。\u0026ldquo;他甚至承认：\u0026ldquo;即使作为公民，我经常感觉我们对民族国家的控制不多。它们失控了。\u0026rdquo;\n关于变革的态度，萨顿认为这取决于你如何看待现状：\u0026ldquo;很多都与你如何看待变革有关。如果你认为当前的情况真的很好，那么你更可能对变革持怀疑和厌恶态度。\u0026ldquo;他个人的立场是：\u0026ldquo;我认为这是不完美的。事实上，我认为这相当糟糕。所以我对变革持开放态度。我认为人类没有超级好的记录。也许这是存在过的最好的东西，但它远非完美。\u0026rdquo;\n当被类比到历史上的革命时，萨顿承认不是所有变革都是好的：\u0026ldquo;工业革命是变革，布尔什维克革命也是变革。\u0026ldquo;他同意我们应该关心变革的方向：\u0026ldquo;我们应该关心我们的未来。我们应该试图让它变好。\u0026ldquo;但他也强调要认识到我们的局限：\u0026ldquo;我们也应该认识到我们的局限。\u0026rdquo;\n13、【与子女类比：如何思考AI的未来】 萨顿用养育子女的类比来思考我们与AI的关系。他认为，就像我们不应该为孩子设定过于具体的人生目标一样，我们也不应该试图完全控制AI的发展方向。\n\u0026ldquo;假设你正在养育自己的孩子。为他们的生活设定极其严格的目标可能不合适。\u0026ldquo;萨顿解释说，过度控制是不现实的：\u0026quot;\u0026lsquo;我希望我的孩子们走出去，在世界上产生这种特定的影响。我的儿子将成为总统，我的女儿将成为英特尔的CEO。他们将一起对世界产生这种影响。\u0026rsquo;\u0026rdquo;\n但他也承认教育价值观的重要性：\u0026ldquo;人们确实有这种感觉——我认为这是合适的——说，\u0026lsquo;我要给他们良好的稳健价值观，这样如果当他们确实最终处于权力位置时，他们会做合理的、亲社会的事情。\u0026rsquo;\u0026rdquo;\n关于价值观的问题，萨顿提出了一个重要观点：\u0026ldquo;有我们都能同意的普遍价值观吗？我不这么认为，但这并不妨碍我们给孩子良好的教育。\u0026ldquo;他建议关注诚信而非特定的道德体系：\u0026ldquo;高诚信可能是一个更好的词。如果有一个看起来有害的请求或目标，他们会拒绝参与。或者他们会诚实，诸如此类。\u0026rdquo;\n萨顿还强调了自愿性的重要性：\u0026ldquo;如果有变化，我们希望它是自愿的，而不是强加给人们的。我认为这是一个非常重要的观点。\u0026ldquo;他认为设计社会的原则\u0026quot;是人类的重大事业之一，已经进行了数千年。\u0026rdquo;\n14、【关于AGI后研究的思考】 访谈中出现了一个有趣的讨论：一旦我们有了AGI，研究会如何发展？提问者提出，届时我们将有\u0026quot;与计算成线性扩展的研究者\u0026rdquo;，可能会有\u0026quot;数百万AI研究者的雪崩\u0026rdquo;。\n萨顿对此持怀疑态度。他首先质疑了前提：\u0026ldquo;我们是如何达到这个AGI的？\u0026ldquo;当被问到是否认为AGI之上还有什么时，他简洁地回答：\u0026ldquo;然后我们就完成了。\u0026ldquo;这表明在他看来，AGI本身就是终点。\n但讨论继续深入到超人类智能的不同级别。提问者举了AlphaGo的例子：\u0026ldquo;AlphaGo是超人类的。它击败了任何围棋选手。AlphaZero会每次都击败AlphaGo。\u0026ldquo;这表明即使在超人类水平上，仍有改进的空间。\n萨顿指出，AlphaZero的改进恰恰是因为它\u0026quot;没有使用人类知识，而只是从经验中学习。\u0026ldquo;他质疑道：\u0026ldquo;当从经验而不是从另一个智能体的帮助中学习效果如此之好时，为什么要\u0026rsquo;引入其他智能体的专业知识来教它\u0026rsquo;？\u0026rdquo;\n关于多个AI如何协作的问题，萨顿提出了一个有趣的困境：\u0026ldquo;你是一个AI，你获得了更多的计算能力。你应该用它来让自己在计算上更有能力吗？还是应该用它来生成一个自己的副本，去地球的另一边或其他主题上学习有趣的东西，然后向你报告？\u0026rdquo;\n15、【数字智能时代的安全挑战】 萨顿提出了一个在数字智能时代特别重要的问题——知识整合的安全性：\u0026ldquo;一个大问题将变成腐败。如果你真的可以从任何地方获取信息并将其带入你的中央思维，你可能会变得越来越强大。\u0026rdquo;\n但这种能力带来了巨大的风险：\u0026ldquo;你可能会以这种方式失去理智。如果你从外部引入某些东西并将其构建到你的内部思维中，它可能会接管你，它可能会改变你，它可能是你的毁灭而不是你知识的增长。\u0026rdquo;\n萨顿详细解释了这个风险：\u0026ldquo;你可能会想，\u0026lsquo;哦，他已经弄清楚了如何玩某个新游戏，或者他研究了印度尼西亚，你想将其纳入你的思维。\u0026lsquo;你可能会想，\u0026lsquo;哦，只要读入所有内容，就会很好。\u0026lsquo;但不，你刚刚将一堆比特读入了你的思维，它们可能包含病毒，它们可能有隐藏的目标，它们可能会扭曲和改变你。\u0026rdquo;\n他预测：\u0026ldquo;这将成为一个大问题。在数字生成和重新形成的时代，你如何拥有网络安全？\u0026ldquo;这个问题在当前的AI安全讨论中还很少被提及，但萨顿认为它将变得至关重要。\n16、【两位图灵奖得主的AI批判：从不同角度走向同一结论】 听完这期访谈，我觉得最有意思的是，现在已经有两位图灵奖得主——强化学习之父理查德·萨顿和深度学习先驱杨立昆——都对大语言模型的主流路线提出了尖锐批评。虽然他们的理论背景和解决方案不同，但在核心判断上惊人地一致。\n两人都认为当前的LLMs存在根本性缺陷。萨顿直言LLMs是\u0026quot;死路一条\u0026rdquo;，因为它们只是在模仿人类说话，而不是理解世界如何运作。杨立昆则频繁指出，LLMs缺乏对物理世界的理解，无法进行真正的推理和规划。他经常用一个生动的比喻：一只普通家猫的智能，在某种意义上比所有LLMs加起来都要强大——因为猫能在三维世界中导航、预测物体运动、理解因果关系，而这些恰恰是LLMs最薄弱的地方。\n在世界模型这个关键问题上，两人的观点高度重合。萨顿强调，真正的世界模型应该能预测\u0026quot;会发生什么\u0026rdquo;，而不仅仅是\u0026quot;人会说什么\u0026rdquo;。杨立昆同样认为，智能系统必须建立世界的内部模型，能够在抽象层面上进行预测和规划。两人都认为，仅仅通过预测文本序列无法获得对世界的真正理解。\n然而，他们提出的解决方案体现了各自的学术背景。萨顿坚持强化学习范式，认为智能的本质是通过\u0026quot;感知-行动-奖励\u0026quot;的循环从经验中学习。他特别强调目标和奖励信号的重要性——没有目标就没有智能，这是他对LLMs最根本的批评。在他看来，我们应该向所有动物学习，包括松鼠如何通过试错来掌握世界。\n杨立昆则提出了JEPA（联合嵌入预测架构），强调在抽象表示空间中进行预测，而非逐个token生成。他更关注自监督学习和分层规划，认为视觉和感知比语言更基础。在他的框架中，能量模型和对比学习是关键技术路径。\n有趣的是，两人都用动物做类比，但角度略有不同。萨顿说\u0026quot;如果我们理解了松鼠，就几乎完全理解了人类智能\u0026rdquo;，强调的是动物共有的基础学习机制。杨立昆说\u0026quot;猫比ChatGPT更智能\u0026rdquo;，强调的是具身智能和对物理世界的理解。这些看似简单的动物，展示了LLMs所缺失的关键能力：真正的学习、适应和理解。\n在对未来的展望上，两人都认为需要范式转变。萨顿预测，一旦我们实现了真正的持续学习系统，它将不需要特殊的训练阶段，而是像所有动物一样即时学习，这将使当前的LLM方法变得过时。杨立昆则认为，下一代AI系统将结合感知、世界模型和规划，形成更接近人类认知架构的系统。\n这种来自不同方向的批判汇聚成一个共同结论：尽管LLMs在某些任务上取得了惊人成就，但它们可能只是通向真正智能的一个弯路。真正的突破需要我们重新思考智能的本质——不是模仿人类的语言输出，而是理解和学习世界的运作方式。正如萨顿所说，\u0026ldquo;弱方法\u0026rdquo;（通用的学习和搜索）最终总是战胜\u0026quot;强方法\u0026rdquo;（人类知识的编码），而当前的LLMs恰恰过度依赖了后者。\n三个核心问题 Q：为什么萨顿认为LLMs从根本上走错了方向？\n萨顿的核心观点是，智能的本质在于从经验中学习并实现目标，而LLMs既没有真正的目标，也无法从经验中学习。它们只是在模仿人类的语言模式，而不是理解世界的因果关系。即使它们能预测下一个token，但这种预测不会改变世界，也不会根据结果调整自己。真正的智能应该像所有动物一样，通过感知-行动-奖励的循环不断学习和适应。\nQ：《苦涩的教训》是否支持扩展LLMs？\n萨顿认为这是对他文章的误读。虽然LLMs确实使用了大规模计算，但它们也严重依赖人类知识（互联网文本），这违背了苦涩教训的精神。历史表明，依赖人类知识的方法最终总会被纯粹基于经验和计算的方法所取代。他预测LLMs会达到数据极限，然后被能够从经验中无限学习的系统所取代，这才是苦涩教训的真正体现。\nQ：AI继承人类是否意味着人类的终结？\n萨顿提出了一个独特视角：这在很大程度上是一个选择问题。我们可以选择将AI视为我们的后代并为之自豪，就像我们为孩子的成就感到自豪一样；也可以选择将其视为威胁。从宇宙演化的角度看，这是从复制时代到设计时代的伟大转变，是宇宙四大阶段之一。与其恐惧这个转变，不如思考如何给予AI良好的价值观，就像我们教育孩子那样，让这个转变以自愿而非强制的方式进行。\n","title":"LLM的根本缺陷"},{"link":"/posts/a%E8%82%A1%E6%AD%A2%E7%9B%88%E6%94%BB%E7%95%A5/","text":"关于A股周期性止盈的思考与策略框架 文档目的： 本文旨在记录个人对于当前A股市场的观察，并基于历史周期性特征，构建一套关于投资止盈的系统性思考与应对框架。\n当前市场背景： 自2024年9月低点至今，市场主要指数出现显著回升（沪深300指数上涨约40%，主动偏股基金指数上涨约50%）。市场情绪由悲观转向乐观，牛市共识逐步形成。在此背景下，有必要对未来的退出策略进行前瞻性规划。\n1. 前提：纠正一个常见的基准误区 在讨论点位与估值之前，必须明确一个有效基准。\n常见误区： 将“上证综合指数”作为衡量A股整体水平的标尺。由于其编制方法未能完全反映市场结构的变化，其参考价值已经失真。\n我的选择： 我主要采用沪深300全收益指数和偏股基金指数作为分析基准。前者更能代表A股市场的核心资产，后者则反映了专业投资者群体的整体表现。后续讨论将基于这两个指数展开。\n2. 论证：A股宽基投资中止盈的必要性 投资策略中是否应包含“止盈”环节，取决于投资标的。\n不适用场景（个人观点）： 个股与窄基行业基金。这类标的的内在价值评估极其复杂，价格与其价值的偏离度难以衡量，因此设定止盈点缺乏可靠依据。此类投资已超出我的能力圈范围。\n适用场景： 宽基指数与全市场型主动基金。这类投资的底层资产是A股经济的整体。基于历史数据和实际经验，A股市场呈现出极强的牛熊周期性。若不进行阶段性止盈，在周期回落时，账面浮盈将面临大幅回撤。尽管长期来看，指数高点会不断抬高，但过程中的波动对投资组合和个人心态均会造成巨大冲击。因此，我判断，针对A股的宽基投资进行周期性止盈是必要的。\n3. 我的策略框架：被动式止盈与主动式止盈 我将止盈策略分为两种模式，它们的核心区别在于决策驱动因素。\n3.1 被动式止盈：基于个人财务状况的调整 该模式的出发点并非预测市场顶部，而是将A股资产视为个人整体财务规划的一部分，根据个人状况进行动态调整。\n情形一：匹配大额消费规划 当存在明确的中远期大额消费需求时（如购车、装修等），可利用牛市带来的资产升值满足此需求。这种卖出行为的动机是改善生活，而非市场择时。即便后续市场继续上涨，由于实现了具体的消费目标，其心理上的“踏空感”会被实际获得感所抵消。\n情形二：通过现金流进行被动仓位再平衡 此方法适用于拥有持续且稳定现金流的投资者。我的操作模式是：设定不同市场估值下的股、债、现金配置比例。当股市上涨导致股票仓位超出目标比例时，将新增的现金流主要投入到债券和现金类资产中，从而使股票仓位的总占比被动下降，达到“减仓”效果，全程无需主动卖出。此模式简化了决策，减少了交易摩擦。\n3.2 主动式止盈：基于市场指标的决策 当投资者存量资金巨大，或市场短期涨幅过快，被动式止盈的调整效果有限时，则需要启动主动式止盈。\n核心工具一：估值指标\n宽基指数： 可参考主流数据服务商（如Wind）提供的指数市盈率（PE）、市净率（PB）等历史百分位。当估值进入90%以上的“高估”或“危险”区域时，可视为一个重要的警示信号。\n主动基金： 主动基金整体难以精确估值。我倾向于使用一些宏观择时信号作为模糊参考，例如“中证800股债性价比”等指标，它们综合了盈利、利率等多重因素，能较好地衡量权益资产的相对吸引力。\n核心工具二：点位指标 基于“牛市高点会超过前一轮高点”的历史规律，可以对本轮牛市的极限空间进行一个粗略的推演。\n沪深300全收益指数： 距离本轮牛市的极限高点，可能存在约**50%**的上涨空间。\n偏股基金指数： 距离本轮牛市的极限高点，可能存在约**80%**的上涨空间。\n重要原则： 上述点位是极限推演，不具备实操中的精确指导性。一个更具操作性的策略是：在指数突破前一轮牛市高点后，开始分批、逐步地执行卖出操作，直至仓位降低到目标水平。\n4. 总结与原则 策略的个体化： 不存在适用于所有人的统一止盈点位。最终决策必须综合考量个人的现金流状况、风险偏好、资金属性以及持仓结构。\n放弃精确，追求合理： 试图卖在最高点的行为是不可取的。所有止盈指标和策略都只能提供一个“模糊的正确”。应当设定一个合理的止盈区间和分批执行计划，接受不完美的结果。这本质上是对市场复杂性的敬畏。\n","title":"A股止盈攻略"},{"link":"/posts/lstm%E8%B0%83%E5%8F%82%E7%BB%8F%E9%AA%8C/","text":"LSTM调参经验\n0、开始训练之前先要做些什么？\n在开始调参之前，需要确定方向，所谓方向就是确定了之后，在调参过程中不再更改\n1、根据任务需求，结合数据，确定网络结构。\n例如对于RNN而言，你的数据是变长还是非变长；输入输出对应关系是many2one还是many2many等等，更多结构参考如下\n 非RNN的普通过程，从固定尺寸的输入到固定尺寸的输出（比如图像分类）输出是序列（例如图像标注：输入是一张图像，输出是单词的序列）输入是序列（例如情绪分析：输入是一个句子，输出是对句子属于正面还是负面情绪的分类）输入输出都是序列（比如机器翻译：RNN输入一个英文句子输出一个法文句子）同步的输入输出序列（比如视频分类中，我们将对视频的每一帧都打标签）\n2、确定训练集、验证集和测试集，并尽可能的确保它们来自相同的分布，并且训练集与测试集的划分通常是7：3，然后在训练集中在进行验证集的划分，验证集的划分可以是交叉验证，也可以是固定比例。\n一旦确定了数据集的划分，就能够专注于提高算法的性能。如果能够保证三者来自相同的分布，对于后续的问题定位也会有着极大的意义。\n例如，某个模型在训练集上效果很好，但是在测试集上的结果并不如意，如果它们来自相同的分布，那么就可以肯定：模型在训练集上过拟合了（overfitting)，那么对应的解决办法就是获取更多的训练集。\n但是如果训练集和测试集来自不同的分布，那么造成上述结果的原因可能会是多种的：\n(i).在训练集上过拟合；(ii).测试集数据比训练集数据更难区分，这时，有必要去进行模型结构，算法方面的修改；(iii).测试集并不一定更难区分，只是与训练集的分布差异比较大，那么此时如果我们去想方设法提高训练集上的性能，这些工作都将是白费努力。\n3、确定单一的评估算法的指标。\n这里需要注意的是，在进行调参之前，我们需要明确我们的目的是什么，是尽可能的分的准（查准率，precision）还是尽可能的找的全（查全率，recall）亦或者两者都要考虑（F1或者ROC曲线下面积）；还或者说，我不仅要关注准确率还要考虑时间效率（此时可以将准确率与算法的运行时间做一个简单的加权，来构建出一个新的指标）。\n我们需要确定使用的指标，并且在优化过程中不再更改，否者你会不知道究竟哪个参数好，因为两个不同的指标之间不容易比较。另外，需要明确使用一个指标，这样能够更加直观的观察不同参数之间的好坏。\n4、对数据进行归一化/标准化处理。\n归一化的原因：统一量纲、便于梯度的计算、加快收敛等\n 归一化之前\n 归一化之后\n归一化：一般采用max-min归一化，使得数据缩放到大小为（-1，1）或者（0，1）之间。\n标准化：z-scores标准化，使得数据整体的均值为0，方差为1。\n对于图像数据的归一化可以采用除以255（如果图像像素在0-255之间）的方式。\n数据归一化的方式是对训练集进行归一化，然后将这种归一化方式应用到验证集和测试集中。\n5、打印你的网络参数个数，与你的数据量进行一个对比。网络越大，功能越强，但也更容易过拟合。不要尝试用10,000个样本来学习一百万个参数。1、开始调参之前先要做些什么？\n1、首先不使用Dropout以及正则化项，使用一个较小的数据集（从原始数据集中取出一小部分），让你的网络去训练拟合这个数据集，看看能否做到损失为0 / 准确率为1 （前提是这个小数据集不能只包含一类样本）。\n2、在一轮epoch中，打印出输入、输出，检测数据的正确性（例如图像数据确保size，其他数据检查是否输入为0，以及检查是否每个batch都是相同的值，检查特征与标签是否对应）\n3、去除正则化项，观察初始的loss值，并对loss进行预估。\n例如，一个二分类问题，使用softmax分类器，那么当样本属于两个类的概率都为0.5的时候，此时的loss = -ln(0.5) = 0.69，后续当网络的loss不再变化时，看看那时候的loss与这个值的关系。如果最终不再变化的loss值等于这个值，那么也就是说网络完全不收敛。\n4、可视化训练过程，在每一轮epoch训练完成后，计算验证集上的loss与准确率（你的评价指标），并记录下每一轮epoch后训练集与验证集的loss与评价指标。如果是图像数据，可以进行每一层的可视化。\n5、如果可以的话，在开始训练之前，尝试用经典的数据集（网上公开数据集，经常在深度学习的网络中使用的数据集，例如MNIST，CIFAR10）先进行训练，因为这些经典数据集都有参考标准（baseline），而且没有数据方面的问题（如噪声、不平衡、随机性过大导致难以学习的问题等等，尤其是在你自己设计了一个新的网络结构时。2、如何调参？\n1、在确保了数据与网络的正确性之后，使用默认的超参数设置，观察loss的变化，初步定下各个超参数的范围，再进行调参。对于每个超参数，我们在每次的调整时，只去调整一个参数，然后观察loss变化，千万不要在一次改变多个超参数的值去观察loss。\n2、对于loss的变化情况，主要有以下几种可能性：上升、下降、不变，对应的数据集有train与val（validation），那么进行组合有如下的可能：\ntrain loss 不断下降，val loss 不断下降——网络仍在学习；\ntrain loss 不断下降，val loss 不断上升——网络过拟合；\ntrain loss 不断下降，val loss 趋于不变——网络欠拟合；\ntrain loss 趋于不变，val loss 趋于不变——网络陷入瓶颈；\ntrain loss 不断上升，val loss 不断上升——网络结构问题；\ntrain loss 不断上升，val loss 不断下降——数据集有问题；\n其余的情况，也是归于网络结构问题与数据集问题中。\n3、当loss趋于不变时观察此时的loss值与1-3中计算的loss值是否相同，如果相同，那么应该是在梯度计算中出现了nan或者inf导致oftmax输出为0。\n此时可以采取的方式是减小初始化权重、降低学习率。同时评估采用的loss是否合理。3、解决方式\n1、当网络过拟合时，可以采用的方式是正则化（regularization）与丢弃法（dropout）以及BN层（batch normalization），正则化中包括L1正则化与L2正则化，在LSTM中采用L2正则化。另外在使用dropout与BN层时，需要主要注意训练集和测试集上的设置方式不同，例如在训练集上dropout设置为0.5，在验证集和测试集上dropout要去除。\n2、当网络欠拟合时，可以采用的方式是：去除 / 降低 正则化；增加网络深度（层数）；增加神经元个数；增加训练集的数据量。\n3、设置early stopping，根据验证集上的性能去评估何时应该提早停止。\n4、对于LSTM，可使用softsign（而非softmax）激活函数替代tanh（更快且更不容易出现饱和（约0梯度））\n5、尝试使用不同优化算法，合适的优化器可以是网络训练的更快，RMSProp、AdaGrad或momentum（Nesterovs）通常都是较好的选择。\n6、使用梯度裁剪（gradient clipping），归一化梯度后将梯度限制在5或者15。\n7、学习率（learning rate）是一个相当重要的超参数，对于学习率可以尝试使用余弦退火或者衰减学习率等方法。\n7、可以进行网络的融合（网络快照）或者不同模型之间的融合。\n","title":"LSTM调参经验"},{"link":"/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%BB%86%E8%8A%82/","text":"机器学习预处理的“潜规则”：数据划分与缺失值处理 在机器学习的实践中，我们常说“数据和特征决定了机器学习的上限，而模型和算法只是在逼近这个上限而已”。这凸显了数据预处理在整个工作流中的核心地位。然而，在预处理的众多环节中，有两个问题常常困扰着初学者，甚至是一些有经验的工程师：\n训练集和测试集的预处理应该如何正确执行？\n面对数据中的缺失值，我们应该如何科学地应对？\n处理不好这两个问题，不仅可能导致模型评估结果虚高，更会使模型在真实世界的应用中表现大打折扣。今天，我们就来深入探讨这两个关键细节。\n黄金法则：始终先划分，再预处理 一个常见的疑问是：我们应该将训练集和测试集合并在一起进行预处理，还是应该分开处理？\n这个问题的答案可以归结为一个核心原则：任何预处理的“学习”过程，都必须且只能在训练集上完成。测试集的作用是模拟模型在未来会遇到的、完全未知的数据。如果在预处理阶段让训练数据“看到”了测试数据的信息（这个过程也称为“数据泄露”），那么模型的评估结果将不再可靠。\n让我们将这个问题拆解为两个层面来理解：\n1. 预处理操作需要保持一致吗？ 需要。 为了保证模型的一致性，训练集和测试集必须经过完全相同的预处理流程。机器学习算法通常假设训练数据和测试数据服从相似的分布。如果在两个数据集上应用了不同的预处理方法，就破坏了这个基本假设，模型将难以泛化。\n2. 预处理的“参数”可以混合计算吗？ 绝对不能。 这是最关键也最容易犯错的地方。当我们进行标准化（计算均值、方差）、归一化（计算最大值、最小值）或者主成分分析（PCA）时，这些转换操作所依赖的“参数”（如均值、方差、主成分向量等）必须仅从训练集中计算得出。\n正确的流程应该是：\n划分数据：首先，将你的数据集划分为训练集和测试集。\n学习参数：在训练集上进行预处理操作的“拟合”（fit），计算出所需的转换参数（例如，StandardScaler的均值和标准差）。\n应用转换：使用上一步学习到的参数，分别对训练集和测试集进行转换（transform）。\n为什么不能混合计算？\n想象一下，在真实的工业应用中，新数据是逐个或分批次到来的。你不可能每次来一个新样本，就把所有历史数据和新数据放在一起重新计算均值和方差，再重新训练模型。正确的做法是，用已经部署好的、基于原始训练数据训练的模型和预处理流程来直接处理新数据。因此，在训练阶段就必须严格遵守这一原则。\n有人可能会说，“把训练集和测试集一起归一化可以提高模型效果”。这是一个典型的伪命题。这种操作带来的“效果提升”仅仅是在这个特定的、被信息污染的测试集上的虚假表现。模型真正的价值在于它对未来未知数据的预测能力，而这种作弊行为恰恰破坏了我们对这种能力的准确评估。\n一个例外：当你已经完成了模型的训练和评估，并准备将其部署为最终产品时，可以把训练集和测试集重新组合成一个更大的数据集，使用之前验证过的最佳模型参数和预处理流程，对全部数据进行重新训练。这样做是为了最大化地利用所有可用数据，以期获得一个更鲁棒的最终模型。\n策略性填补：如何优雅地处理缺失值 数据缺失是现实世界中不可避免的问题。对于如何处理缺失值，业界没有一成不变的“标准答案”，但我们可以根据项目的目标来制定合理的策略。这里我们主要讨论数据是随机缺失的情况。\n一个常见的说法是，缺失率在20%以内的变量可以考虑填补，但具体情况还需具体分析，核心在于区分研究的目标是因果推断还是预测建模。\n1. 面向因果推断的研究 因果推断旨在分析变量间的因果关系，对数据的真实性和完整性要求极高。因此，对缺失值的容忍度较低。\n使用简单填补法：如果你计划使用均值、中位数或末次观测值结转（LOCF）等机械填补方法，建议变量的缺失率控制在 10% 以内。因为这些方法会扭曲数据的原始分布，较高的缺失率会引入显著的偏倚。\n使用高级填补法：如果采用多重填补（Multiple Imputation）等利用数据间关联性进行填补的策略，可以将缺失率的容忍度放宽到 20% 左右。\n2. 面向预测模型的研究 与因果推断不同，预测建模的核心目标是构建一个在内部和外部数据上都表现一致、预测能力强的模型。它更关注结果的准确性和稳健性，而非变量间的因果解释。\n在这种场景下，我们对缺失值的容忍度可以更高。只要你的填补策略能帮助建立一个在外部验证中表现良好的模型，那么这个策略就是合理的。预测模型的最终裁判是外部验证的结果。\n缺失率上限：对于预测模型，缺失率在 30% 以内的变量通常都可以尝试保留和填补。\n验证是关键：关键在于，填补后建立的模型必须经过严格的验证。最理想的是使用一个独立的外部数据集进行验证。如果没有，也可以将原始数据中的完整病例作为验证集，来检验模型的稳健性。\n说得极端一点，如果你的模型（哪怕数据是模拟生成的）能够在外部验证中持续获得优异且一致的结果，那么你的数据处理方式就是成功的。当然，缺失比例过高的数据在填补后容易失真，这样的模型通常很难通过严格的验证性分析。\n","title":"机器学习中的数据预处理细节"},{"link":"/posts/once_upon_a_time_in_america/","text":"美国起飞那一代人的两条路。\n面条这条路就是传统美国男性的那条路，恪守准则，捍卫朋友，相信爱情，这条路艰难，痛苦，熬人（阿尔帕西诺在闻香识女人中说过，这条路唯一的问题就是太尼玛疼），唯一的好处是不会让你死于绝望和精神自杀。\n随后导演指出美国从二十年代到六八年，就是一个用社会机制把这些传统的美国男性搞到死的历史，沉默，坚韧，勇敢的美国即将让位于聒噪，轻佻的美国。面条是老派的，朋友信任他，高层畏惧，赏识他，女人迷恋他，面条愿意为朋友杀人，坐牢，愿意为了一个女人一辈子不结婚，愿意相信麦尔斯已经死了，愿意捍卫自己的童年生活，面条恪守这些信条，这些信条让他拥有了友谊，忠诚，地位，爱情，和财富，也让他遭到背叛，欺骗和荒废。\n但是面条并没有认为老派一点是错的，命运最终要揭晓结局，在揭晓结局的这个晚上，你会发现，黛博拉不能接受自己生了麦尔斯的儿子，不能接受让面条看到这一点，麦尔斯不能接受自己孤零零的死去，想在生命的最后一刻死在面条手里，欺骗自己说自己好歹还了一点债，但是面条接受这一切，而且是平静如水地接受这一切。\n在最后的决斗中，麦尔斯不能再欺骗自己，他这辈子也没有战胜面条，哪怕一次。\n面条说：“我们接受一些委托，拒绝另一些，杀您，这是我们不会做的事情。”\n我们，us,united states。面条将麦尔斯无情地从帮派开除了出去。你不再是我们的一份子了。哪些死的人还是我们的一份子，你虽然活着，但已经不是了。\n黛博拉和麦尔斯则不是这样的人，黛博拉为了站上顶端，放弃了爱情，再用余生来确定自己其实只爱面条一个人，并且等了面条几十年。麦尔斯怂了，麦尔斯害怕了，麦尔斯觉得按照面条这种混法永远不能成为贝利部长，麦尔斯用假死和欺骗吞并了兄弟们的共有财产，再用余生来欺骗自己，说自己比面条要更成功，而事实上是什么呢？事实上，在麦尔斯选择欺骗自己的那天起，他就是工会的傀儡，现在，工会需要他去死了，幻境破灭了，他终于不得不承认自己一直是热爱面条这条路的，这条路让他免于被操纵和恐惧，只是他没有勇气去跟着面条走下去。一开始，他以为自己嫉妒其他人看面条时的那种无比崇拜，无限信任的眼神，后来他才知道他看面条时的眼神其实也是那样子的。\n麦尔斯到死都没有勇气，他害怕面对法庭，他逃避了一辈子，最终只是个自了汉。\n美国往事就是通过这种对比，来揭示基督教世界的元叙事：受难的，要成圣。说谎的，要下地狱。在所有欺骗中，欺骗自己是最不可饶恕的那一种。黛博拉以为自己有了地位就可以没有爱情，奈尔思以为自己当了部长就能实现人生理想，但是到生命的最后时刻，他们都无法逃离面条。最终他们屈服了，尤其是麦尔斯，他彻底地屈服了，他只想死在兄弟手里，但是兄弟已经将其开除，并且干脆地拒绝了他。\n这个时候，六八年的年轻人开着敞篷车经过了，历史在一九六八年完成了断代。\n一九六八年之后的美国是另一个国家，一个会用视听媒体让你不明白自己的生活为什么不对劲或者为什么感觉良好的国家，此后的美国母题就进入了另一种叙事，美国人在进入社会的时候是懵懂的，是没有面条这种天然存在的行为规范的，老白必须经历种种刺激，才能明白没有这些行为规范的美国社会是多么的潮湿而庞杂，和面条相比，老白必须通过种种斗争，才能重新确立一条自己认可的行为准则，那么，这个时候，老白就不可能再有看淡一切的晚年了。\n他醒的太晚了。\n老白死后的数年后，美帝心理学协会认为：“传统男子气概是有害的。”\n一九六八年的美国已经死去，电视的统治结束了，社交媒体的统治建立了，一个用聒噪和轻佻都无法形容的美国诞生了。\n美国往事这个电影好在哪里呢？好就好在这些宗教式的说教他是融合在生活细节里让你慢慢品的。当然这不够，这只是佳作的水平，真正让美国往事更上层楼的是这个作品的命运，资本不接受四个小时的叙事，将其切成两个小时并且导致了理所当然的票房惨败，导演因此郁郁而终。\n那么到了这一步，美国往事的伟大就无人能撼动了。他和电影中的人物享受了同样的命运，完成了同构。面条——美国往事——曾经的美国，一切，随风而逝。\n","title":"Once_Upon_a_Time_in_America"},{"link":"/posts/clustering_algorithms/","text":"在数据科学和机器学习领域，聚类算法是一项核心的无监督学习技术。与需要预先标记数据的监督学习不同，聚类算法旨在探索数据的内在结构，将相似的数据点自动分组，形成不同的“簇”或“群组”。其核心思想是“物以类聚，人以群分”，使得同一簇内的数据点尽可能相似，而不同簇之间的数据点尽可能相异。\n什么是聚类？ 想象一下，你面前有一堆混杂的水果，你需要将它们分类。你可能会根据颜色、形状、大小等特征，自然地将苹果、香蕉和橙子分开。聚类算法做的就是类似的事情，只不过处理的是抽象的数据。这些数据点可以是用户画像、文档、图像像素，甚至是基因序列。\n聚类算法的目标是发现数据中的自然分组，这个过程不需要任何先验知识或标签。因此，它在探索性数据分析、客户分群、异常检测、图像分割等众多领域都有着广泛的应用。\n主流聚类算法类型 聚类算法种类繁多，适用于不同的数据结构和分析目标。主流的算法可以分为以下几大类：\n1. 划分式聚类 (Partitioning Clustering) 这类算法试图将数据集分割成预先指定数量（K）的、不重叠的簇。它通过优化某个标准（如最小化簇内距离之和）来迭代地为每个数据点分配归属。\n代表算法：K-Means (K-均值)\nK-Means 是最著名和最简单的聚类算法之一。其工作流程直观易懂：\n初始化: 随机选择 K 个数据点作为初始的“质心”（每个簇的中心）。\n分配: 计算每个数据点到各个质心的距离（通常是欧氏距离），并将其分配给最近的质心所在的簇。\n更新: 重新计算每个簇的质心，即该簇内所有数据点的平均值。\n迭代: 重复步骤2和3，直到质心的位置不再发生显著变化，或者达到预设的迭代次数。\n优点:\n算法简单、快速，对于处理大规模数据集效率很高。\n当簇是凸形且大小相似时，效果很好。\n缺点:\n需要预先手动指定簇的数量 K，而 K 值的选择往往很困难。\n对于初始质心的选择非常敏感，不同的初始选择可能导致完全不同的聚类结果。\n对于非凸形状的簇、大小不一的簇以及存在异常点的数据集，效果不佳。\n应用场景: 客户分群、产品分类、文档主题聚类。\n2. 层次聚类 (Hierarchical Clustering) 层次聚类算法会创建一个簇的层次结构，可以形象地表示为一棵树状图（Dendrogram）。它主要有两种策略：\n凝聚式 (Agglomerative): “自底向上”的方法。开始时，每个数据点都是一个独立的簇，然后迭代地将最相似的两个簇合并，直到所有数据点都合并成一个簇。\n分裂式 (Divisive): “自顶向下”的方法。开始时，所有数据点都在一个大簇里，然后迭代地将最不相似的簇分裂成两个，直到每个数据点都自成一簇。\n优点:\n不需要预先指定簇的数量。可以根据树状图在不同层次上进行“切割”，从而获得任意数量的簇。\n可以揭示数据之间的层次关系。\n缺点:\n计算复杂度较高，特别是对于大数据集。\n一旦合并或分裂完成，就无法撤销，这可能导致次优的聚类结果。\n对于选择哪种合并/分裂策略以及距离度量方法比较敏感。\n应用场景: 生物学中的物种分类、社交网络分析、购物篮分析。\n3. 基于密度的聚类 (Density-Based Clustering) 这类算法将簇定义为数据空间中被低密度区域分隔开的高密度区域。它能够发现任意形状的簇，并且能有效地识别出噪声点。\n代表算法：DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\nDBSCAN 的核心思想是，只要一个点的邻域内（由半径 ε 定义）包含足够多的其他点（由数量 MinPts 定义），那么这个点就被视为一个核心点。\n核心点: 在其 ε 邻域内有至少 MinPts 个点的点。\n边界点: 在某个核心点的 ε 邻域内，但自身不是核心点的点。\n噪声点: 既不是核心点也不是边界点的点。\n聚类过程就是从任意一个核心点开始，不断扩张，将所有密度可达（即通过核心点连接起来）的点划分为同一个簇。\n优点:\n能够发现任意形状的簇，对圆形簇和非圆形簇都有效。\n能够识别并处理噪声点和异常值。\n不需要预先指定簇的数量。\n缺点:\n对于密度不均匀的数据集效果不佳。\n对于高维数据，密度定义困难（维度灾难），ε 和 MinPts 两个参数的选择对结果影响很大。\n应用场景: 异常检测（如金融欺诈检测）、地理空间数据分析、图像识别。\n4. 基于模型的聚类 (Model-Based Clustering) 这类算法假设数据是由一个或多个潜在的概率分布混合生成的。聚类的目标是找到最能拟合数据的模型。\n代表算法：高斯混合模型 (Gaussian Mixture Model, GMM)\nGMM 假设所有数据点都是从多个高斯分布（正态分布）的混合中生成的。每个高斯分布对应一个簇。算法通过期望最大化 (EM) 算法来估计每个高斯分布的参数（均值、方差）以及每个数据点属于各个簇的概率。\n优点:\n提供了“软”聚类，即每个数据点可以属于多个簇，并给出了属于每个簇的概率。\n由于考虑了协方差，因此可以适应不同形状的簇（如椭圆形）。\n缺点:\n算法较为复杂，计算成本较高。\n需要预先指定分布的数量（即簇的数量）。\n其假设（数据服从高斯分布）可能与实际数据不符。\n应用场景: 图像分割、语音识别、金融市场分析。\n如何选择合适的聚类算法？ 选择哪种聚类算法并没有统一的标准答案，通常取决于数据的特性、规模以及分析的目标。以下是一些指导原则：\n特性 K-Means 层次聚类 DBSCAN 簇的形状 倾向于球形 任意形状 任意形状 需要指定K值 是 否 否 (但需指定ε和MinPts) 处理噪声 敏感 敏感 鲁棒 计算复杂度 较低 较高 中等 大数据集 适用 不太适用 适用 可解释性 较好 好 (树状图) 中等 K-Means++ K-Means++ 不是一个全新的聚类算法，而是对标准 K-Means 算法的一个关键优化，专门改进其初始质心（initial centroids）的选择方法。 这个优化的核心目标是解决标准 K-Means 算法对初始点选择过于敏感的致命弱点，从而使其聚类结果更稳定、更准确。\n标准 K-Means 的痛点：糟糕的初始化 要理解 K-Means++ 的精妙之处，我们必须先回顾一下标准 K-Means 的问题。\n标准 K-Means 算法的第一步是随机在数据点中选择 K 个点作为初始质心。这种完全随机的方式存在一个巨大风险：\n运气不佳的开局： 如果运气不好，选中的 K 个初始质心可能挤在一起，或者都落在某一个数据簇中。\n陷入局部最优： 从一个糟糕的初始状态出发，算法很可能在后续的迭代中陷入一个“局部最优解”，而不是“全局最优解”。这意味着最终得到的聚类结果可能非常差，完全没有反映出数据的真实结构。\n结果不稳定： 每次运行标准 K-Means，由于初始质心的随机性，你可能会得到完全不同的聚类结果。\n想象一下，你要将一个城市的人口分为几个中心社区，如果一开始就把所有社区中心都选在了市中心最繁华的地段，那么郊区的居民就很难被合理地划分。\nK-Means++ 的解决方案：更智能的初始化 K-Means++ 的提出就是为了解决这个问题。它不再是完全随机地选择初始质心，而是采用一种更具策略性的、基于概率的抽样方法，确保初始质心之间尽可能地相互远离。\n这种“广撒网”式的初始化策略，极大地提高了找到高质量聚类结果的可能性。\nK-Means++ 的初始化步骤 它的具体初始化流程如下：\n选择第一个质心： 从数据集中随机选择一个数据点作为第一个质心（c1​）。\n这一步和标准 K-Means 一样，是唯一的完全随机步骤。 选择后续的质心 (第 2 个到第 K 个)： 对于数据集中的每一个非质心点 x，计算它与当前已有的所有质心之间的最短距离。这个距离我们记为 D(x)。\n例如，在选择第二个质心 c2​ 时，D(x) 就是每个点到 c1​ 的距离。在选择第三个质心 c3​ 时，D(x) 就是每个点到 c1​ 和 c2​ 中较近那个的距离。 按概率选择下一个质心： 下一个质心会从所有数据点中通过轮盘赌选择法 (Roulette Wheel Selection) 选出。每个数据点 x 被选为新质心的概率与它的 D(x)2 成正比。\n核心思想： 距离现有质心越远的点，其 D(x)2 的值就越大，因此它被选中成为下一个质心的概率也就越大。这确保了新的质心会优先在远离现有质心群的区域产生。 重复步骤 2 和 3： 不断重复这个过程，直到选出总共 K 个质心。\n运行标准 K-Means： 当 K 个初始质心都通过上述方法选定后，接下来的步骤就和标准 K-Means 算法完全一样了：进行分配（Assignment）和更新（Update）两个步骤，直到质心位置收敛。\nK-Means++ 的优势 与标准 K-Means 相比，K-Means++ 的优势非常明显：\n更好的聚类质量： 通过让初始质心分布得更开，K-Means++ 能显著提高最终聚类结果的质量（通常用簇内平方和 SSE 来衡量），使其更有可能收敛到全局最优解或一个非常接近全局最优解的结果。\n更快的收敛速度： 虽然 K-Means++ 的初始化阶段比纯随机选择要慢一些，但由于它提供了一个非常好的“起点”，后续 K-Means 的迭代次数会大幅减少。总体而言，总运行时间通常反而更短。\n结果更稳定： 摆脱了对纯粹随机性的依赖，多次运行 K-Means++ 通常会得到相似甚至相同的高质量结果。\n总结 可以这样理解：\nK-Means：一个不错的聚类算法，但非常依赖“开局运气”。\nK-Means++：给 K-Means 算法加装了一个“智能导航系统”来进行初始化。它花了一点时间来规划路线（选择初始质心），确保从一个绝佳的位置出发，从而更快、更准地到达目的地（高质量的聚类结果）。\n在实践中，由于其出色的性能和稳定性，K-Means++ 已经成为绝大多数机器学习库（如 Scikit-learn）中 K-Means 算法的默认初始化策略。当你调用 KMeans() 时，通常后台使用的就是 K-Means++ 的初始化方法。\n","title":"Clustering_Algorithms"},{"link":"/posts/introduction_to_pcb/","text":"1. 电路设计 1.1 原理图四要素 元件符号 连接线 结点 注释 1.2 基本原件介绍 1.2.1 电阻 对于贴片电阻的读数 1）3位读数：前2位为有效数字，第3位表示10的n次幂(也可以理解为0的个数)。精度为±5%\n2）4位读数：前3位为有效数字，第4位表示10的n次幂(也可以理解为0的个数)。读法和3位的原理一样，精度为±1%\n3）阻值小于10的读数：通常在两个数之间插入一个字母R，用字母R来代替小数点\n1.2.2 电容 主要功能：储能和滤波\n单位计算\n1uF=1000nF；1nF=1000pF\n分类 读数以及含义\n1.2.3 电感 ​ Inductor，\n单位换算 1H=1000mH；1mH=1000uH；\n主要功能：滤波，扼流，谐振，储能 分类 读数以及含义 1.2.4 二极管 主要功能 ​ 实现对交流电整流、对调制信号检波、限幅和钳位以及对电源电压的稳压等多种功能 。\n分类以及简单介绍 外观（判断正负极） 对于直插式发光二极管：长脚为正极，内部小块为正极。 一般封装类型的正负极判断 \n1.2.5 三极管 分类：NPN（控地） 和 PNP（控电源）\n工作状态\n截止状态 ​ 发射结反偏，集电结反偏。即：I ce=0\n放大状态 ​ 发射结正偏，集电结反偏。\n饱和状态发射结正偏，集电结正偏 常见封装 \n1.2.6 场效应管（尚未掌握） 基本介绍 ​ 场效应晶体管（Field Effect Transistor缩写(FET)）简称场效应管。它是利用控制输入回路的电场效应来控制输出回路电流的一种半导体器件。\n特点 ​ 具有输入电阻高、噪声小、功耗低、动态范围大、易于集成、没有二次击穿现象、安全工作区域宽等优点。\n类型 结型场效应管（junction FET—JFET)\n金属 - 氧化物半导体场效应管（metal-oxide semiconductor FET，简称MOS-FET）\n与三极管的对比 \n封装 \n\n\n1.2.7 芯片 / IC ==具体见数据手册==1.3 数据手册\n自己找去1.4 电路原理图设计\n网络标签 ​ 网络标签 (Net Label)：网络标号表示一个电器连接点，具有相同网络标号的器件表明是电气连接在一起。\n模块化 注释 总结： 分模块、分图页\n标注重要参数\n标注元件特殊/重要功能\n标注注意事项\n合理的网络标签\n标注LOGO/版本号\n==成功的原理图设计=合理的元件选型+正确的电路设计==2. PCB设计\nPCB基本介绍 ​ PCB板就是印制电路板，又称印刷电路板，是电子元器件电气连接的提供者。PCB根据其基板材料的不同而不同，高频微波板、金属基板，铝基板、铁基板、铜基板、双面板及多层板PCB是英文Printed Circuit Board的缩写，中文名称为印制电路板，又称印刷电路板、印刷线路板，是重要的电子部件。\n2.1PCB 组成 2.1.1铺铜 作用 ​ 将PCB上闲置的空间作为基准面，然后用固体铜填充，这些铜区又称为灌铜。覆铜的意义在于，减小地线阻抗，提高抗干扰能力；降低压降，提高电源效率；与地线相连，还可以减小环路面积。\n方式 大面积覆铜 ​ 大面积覆铜，具备了加大电流和屏蔽双重作用，但是大面积覆铜，如果过波峰焊时，板子就可能会翘起来，甚至会起泡。因此大面积覆铜，一般也会开几个槽，缓解铜箔起泡。低频电路、有大电流的电路等常用大面积的覆铜。\n网格覆铜 从散热的角度说，它降低了铜的受热面，又起到了一定的电磁屏蔽的作用。因此，高频电路对抗干扰要求高的多用网格覆铜\n2.1.2过孔 功能 电气连接：过孔用于将不同层面的电路连接起来，使得电路板能够在不同的层次上进行有效的信号和电源传输。 器件固定或定位：过孔还可以用作固定电子部件的位置，如电阻、电容等，确保其在电路板上的正确布局。 分类 通孔：从PCB的上层钻到底层的机械钻孔。 盲孔：从 PCB 的上层或底层到内层钻孔和电镀的孔。 埋孔：指位于印刷线路板内层的连接孔，它不会延伸到线路板的表面。 2.1.3焊盘 定义： ​ 元件通过PCB上的引线孔，用焊锡焊接固定在PCB上，印制导线把焊盘连接起来，实现元件在电路中的电气连接。引线孔及周围的铜箔称为焊盘。\n2.1.4丝印 ​ PCB丝印是指在电子线路板（Printed Circuit Board）上印刷的信息，如文字、标志、图形等。这些丝印具有重要的功能，它们可以帮助标识电子元件的位置、数值、型号等信息，以及元件的方向和正确的安装方式。\n2.1.5阻焊 ​ 在铜层上面覆盖油墨层，油墨层覆盖住铜层上面不需要焊接的线路，防止PCB上的线路和其他的金属、焊锡或者其它的导电物体接触导致短路，起到绝缘及保护铜层作用，选择性露出焊接需要的铜PAD、IC等。\n2.2PCB结构 叠层结构 ​ PCB材料的组成主要有PP半固态片和Core芯板两部分组成，这就构成了所看到的绿色、红色或者黑色等的板子，再加上敷铜线路层，器件，就构成了电路板。\n==叠层结构布局有讲究==，但是一般的二层板双面都可能需要走底地线和电源。 图示 \n2.3 PCB设计流程 \n2.end.1PCB设计规则总览（持续添加ing） 电路布局与元器件安放：\n电路布局是否合理？\n元器件之间的距离是否足够？\n元器件的放置方向是否一致？\n是否合理安排了元器件的布局顺序？\n是否考虑了元器件的封装形式和选择？\n是否进行了元器件的标注和排列规范？\n是否考虑了元器件的插拔次数和位置？\n是否进行了元器件的冗余设计？\n是否考虑了元器件的热管理和散热问题？\n是否进行了元器件的可靠性分析？\n信号管理：\n线宽与过孔1）8/8mil，过孔选择12mil（0.3mm）。2）6/6mil，过孔选择12mil（0.3mm）。3）4/4mil，过孔选择8mil（0.2mm）。4）3.5/3.5mil，过孔选择8mil（0.2mm）。5）3.5/3.5mil，过孔选择4mil（0.1mm，激光打孔）。6）2/2mil，过孔选择4mil（0.1mm，激光打孔）。参考过孔：内径12mil、外径20mil参考内径20mil、外径30mil\n是否进行了信号完整性分析？\n是否进行了阻抗匹配设计？\n是否进行了信号线路的优化布局和仿真验证？\n是否考虑了电磁干扰和射频干扰的影响？\n是否进行了电磁场模拟分析？\n是否考虑了信号传输速率和衰减问题？\n是否考虑了线路的阻抗匹配和信号损耗？\n是否进行了线路的阻抗匹配设计？\n电源管理：\n电流与布线宽度\n电源线、地线的宽度最好尽可能宽，地线比电源线宽。这些关系为：地线\u0026gt;电源线\u0026gt;信号线，通常信号线的宽度为0.2-0.3mm(8-12mil)，最细的宽度为0.05-0.07mm(2-2.8mil)，电源线为1.2-2.5mm(48-100mil)。(0.025mm=1mil).PCB走线载流计算器-EDA365电子论坛通信数码-人工智能-计算机-半导体-手机家电消费电子硬件门户网站\n是否考虑了电源的滤波和稳压？\n是否进行了电源线和地线的分离和规范设计？\n是否考虑了过压和过流保护的设计？\n是否进行了电源供应的充足性和稳定性分析？\nPCB工艺与环境因素：\n是否考虑了PCB的工作环境和应用场景\n是否进行了PCB的加工工艺和成本分析？\n是否进行了PCB布线的仿真验证？\n是否考虑了PCB的防火、加固、环境友好等设计因素？\n","title":"Introduction_to_PCB"},{"link":"/posts/auto_deploy/","text":"Github Action自动部署 （1）Github创建一个新的仓库，用于存放Hugo的主文件\n（2）前往Setttings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens，创建一个token(classic)\n（3）token选择永不过期，并勾选 repo 和 workflow 选项 （4）为保证安全，将生成的token，保存的仓库的变量中，前往Settings -\u0026gt; Secrets and variables -\u0026gt; Actions中设置 （5）在hugo主文件创建一个.github/workflows/xxxx.yaml文件，将以下内容复制进去，想具体了解更多，可查看【Github Action文档】 1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34 name: deploy\n# 代码提交到main分支时触发github action\non:\npush:\nbranches:\n- main\njobs:\ndeploy:\nruns-on: ubuntu-latest\nsteps:\n- name: Checkout\nuses: actions/checkout@v4\nwith:\nfetch-depth: 0\n- name: Setup Hugo\nuses: peaceiris/actions-hugo@v3\nwith:\nhugo-version: \u0026ldquo;latest\u0026rdquo;\nextended: true\n- name: Build Web\nrun: hugo -D\n- name: Deploy Web\nuses: peaceiris/actions-gh-pages@v4\nwith:\nPERSONAL_TOKEN: ${{ secrets.你的token变量名 }}\nEXTERNAL_REPOSITORY: 你的github名/你的仓库名\nPUBLISH_BRANCH: main\nPUBLISH_DIR: ./public\ncommit_message: auto deploy （6）在hugo主文件创建.gitignore文件，来避免提交不必要的文件 1\n2\n3\n4\n5\n6\n7 # 自动生成的文件\npublic\nresources\n.hugo_build.lock\n# hugo命令\nhugo.exe （7）将hugo的主文件上传到仓库，上传成功后会触发Github Action，来自动部署你的静态页面 1\n2\n3\n4\n5\n6 git init\ngit add .\ngit commit -m \u0026ldquo;first commit\u0026rdquo;\ngit branch -M main\ngit remote add origin {你的github仓库地址}\ngit push -u origin main ","title":"Auto_deploy"},{"link":"/posts/myfirstblog/","text":"加密市场笔记 心理建设 在心理上预测行情就行了，但一定不要轻举妄动，要等待，直到你从市场上得到证实你的判断是正确的信号，到了那个时候，而且只有到了那个时候，你才能用你的钱去进行交易。\n小规律 通常8月、9月\u0026#x1f4b5;难赚。\n","title":"MyFirstBlog"},{"link":"/posts/test-alert/","text":"GitHub Style Alert Testing This article is used to test the new GitHub-style Alert feature and folding functionality.\nAlert Syntax Note Alert Note This is a note alert box. Used to display useful information that users should be aware of, even when quickly browsing the content.\nTip Alert Tip This is a tip alert box. Provides suggestions that help complete tasks better or more easily.\nImportant Alert Important This is an important alert box. Displays critical information users need to know to achieve their goals.\nWarning Alert Warning This is a warning box. Urgent information that requires immediate user attention to avoid problems.\nCaution Alert Caution This is a caution alert box. Advises users to be aware of the risks or negative consequences of certain behaviors.\nExtended Syntax - Custom Titles Note with Custom Title Custom Title This is a note alert box with a custom title.\nWarning with Custom Title Radiation Hazard Do not approach or handle without protective equipment.\nFolding Feature Expanded Foldable Alert by Default Click to Collapse This is an expanded foldable alert box by default. Click the title to collapse the content.\nSupports multi-line content:\nList item 1 List item 2 List item 3 Collapsed Alert by Default Important Information (Collapsed by Default) This is an important information box collapsed by default. Click the title to expand and view the content.\nCan include:\nOrdered list Bold text Italic text Code snippet Foldable Alert with Complex Content Complex Content Example This foldable box contains complex Markdown content:\nSubheading This is a paragraph containing a link and other formatting.\nJAVASCRIPT 行号 Collapse Copy 1// Code block example 2function hello() { 3 console.log(\u0026#34;Hello, World!\u0026#34;); 4} Click to expand and view more Table Example Row1 Data1 Row2 Data2 Regular Blockquote This is a regular blockquote, not an Alert:\nThis is a standard blockquote. It won\u0026rsquo;t be rendered as an Alert but will use the standard blockquote styling.\nSupports multi-line content and formatted text.\nMultilingual Support Alerts support multiple languages, and titles will automatically display in the current language:\nNote In a Chinese environment, this title will display as \u0026ldquo;注意\u0026rdquo; (Note).\nTip In a Chinese environment, this title will display as \u0026ldquo;提示\u0026rdquo; (Tip).\nNested Content Test Nested Content Test This Alert contains nested content:\nThis is a nested blockquote\nList item Nested list item Another nested item Ordered list Nested ordered list Another nested item ","title":"GitHub Style Alert Test"},{"link":"/posts/%E7%9B%AE%E5%BD%95%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/","text":"目录功能测试 这是一篇用于测试侧边目录功能的文章。\n第一章：基础功能 这是第一章的内容，用于测试目录的生成和显示。\n1.1 子章节 这是子章节的内容。\n1.1.1 更深层次 这是更深层次的章节。\n1.2 另一个子章节 这是另一个子章节的内容。\n第二章：高级功能 这是第二章的内容。\n2.1 功能特性 这里描述了一些功能特性。\n2.2 使用方法 这里说明了使用方法。\n第三章：总结 这是总结章节。\n3.1 优点 这里列出了优点。\n3.2 改进建议 这里提出了改进建议。\n结语 测试文章到此结束。\n","title":"目录功能测试文章"},{"link":"/posts/katex-and-mermaid-test/","text":"KaTeX and Mermaid Test This article is used to test the KaTeX and Mermaid features.\nConfiguration Frontmatter Configuration YAML 行号 Collapse Copy 1--- 2katex: true 3mermaid: true 4--- Click to expand and view more Global Configuration YAML 行号 Collapse Copy 1# hugo.yaml 2katex: 3 enabled: true 4 delimiters: 5 - left: \u0026#34;$$\u0026#34; 6 right: \u0026#34;$$\u0026#34; 7 display: true 8 - left: \u0026#34;$\u0026#34; 9 right: \u0026#34;$\u0026#34; 10 display: false 11 12mermaid: 13 enabled: true Click to expand and view more KaTeX Test Inline Formula This is an inline formula: $E = mc^2$, Einstein\u0026rsquo;s mass-energy equivalence formula.\nAnother example：When $a \\neq 0$, the solutions to the quadratic equation $ax^2 + bx + c = 0$ are $x = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$.\nBlock Formula Quadratic Formula $$x = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$$\nEuler\u0026rsquo;s Formula $$e^{i\\pi} + 1 = 0$$\nIntegral Formula $$\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}$$\nMatrix Representation $$\\begin{pmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} ax + by \\\\ cx + dy \\end{pmatrix}$$\nSummation Formula $$\\sum_{n=1}^{\\infty} \\frac{1}{n^2} = \\frac{\\pi^2}{6}$$\nCommon Mathematical Symbols Test Using predefined macros: $\\RR$, $\\NN$, $\\ZZ$, $\\QQ$, $\\CC$\n","title":"KaTeX and Mermaid Test"},{"link":"/posts/image-rendering-test/","text":"Image Rendering Test The Demo comes from LightGallery All images are from Unsplash\nSingle Image Photo by - Daniel Leone Justified Gallery Photo by - Tobias Rademacher Photo by - Massimiliano Morosinotto Photo by - Sascha Bosshard Photo by - Yusuf Evli Photo by - Jay Mantri Photo by - Florian van Duyn Photo by - Juan Davila Photo by - David Marcu Masonry by shortcodes ","title":"Image Rendering Test"},{"link":"/posts/code-highlighting-test/","text":"Code Highlighting Test This article is used to test the new code highlighting feature, including syntax highlighting, copy button, language display, etc.\nJavaScript JAVASCRIPT 行号 Collapse Copy 1 2function fibonacci(n) { 3 if (n \u0026lt;= 1) return n; 4 return fibonacci(n - 1) + fibonacci(n - 2); 5} 6 7 8const result = fibonacci(10); 9console.log(`The 10th Fibonacci number is: ${result}`); 10 11// Async/Await 12const asyncFunction = async () =\u0026gt; { 13 try { 14 const response = await fetch(\u0026#39;/api/data\u0026#39;); 15 const data = await response.json(); 16 return data; 17 } catch (error) { 18 console.error(\u0026#39;Error fetching data:\u0026#39;, error); 19 } 20}; Click to expand and view more Codeblock with Line Numbers PYTHON 行号 Collapse Copy 1# Python with line numbers 2import asyncio 3from typing import List, Optional 4 5class DataProcessor: 6 def __init__(self, data: List[dict]): 7 self.data = data 8 9 def process(self) -\u0026gt; Optional[dict]: 10 \u0026#34;\u0026#34;\u0026#34;Process the data and return the result\u0026#34;\u0026#34;\u0026#34; 11 if not self.data: 12 return None 13 14 result = { 15 \u0026#39;total\u0026#39;: len(self.data), 16 \u0026#39;processed\u0026#39;: [] 17 } 18 19 for item in self.data: 20 if self.validate_item(item): 21 result[\u0026#39;processed\u0026#39;].append(item) 22 23 return result Click to expand and view more Highlighting Specific Lines GO 行号 Collapse Copy 1package main 2 3import \u0026#34;fmt\u0026#34; // This line will be highlighted 4 5func main() { 6 message := \u0026#34;Hello, World!\u0026#34; // This line will also be highlighted 7 8 fmt.Println(message) // This line will also be highlighted 9 10 for i := 0; i \u0026lt; 3; i++ { 11 fmt.Printf(\u0026#34;Count: %d\\n\u0026#34;, i) 12 } 13} Click to expand and view more Codeblock with Filename api.ts 行号 Collapse Copy 1// TypeScript API 2interface ApiResponse\u0026lt;T\u0026gt; { 3 data: T; 4 status: number; 5 message: string; 6} 7 8interface User { 9 id: number; 10 name: string; 11 email: string; 12 avatar?: string; 13} 14 15class ApiClient { 16 private baseURL: string; 17 private headers: Record\u0026lt;string, string\u0026gt;; 18 19 constructor(baseURL: string, apiKey?: string) { 20 this.baseURL = baseURL; 21 this.headers = { 22 \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, 23 ...(apiKey \u0026amp;\u0026amp; { \u0026#39;Authorization\u0026#39;: `Bearer ${apiKey}` }) 24 }; 25 } 26 27 async get\u0026lt;T\u0026gt;(endpoint: string): Promise\u0026lt;ApiResponse\u0026lt;T\u0026gt;\u0026gt; { 28 const response = await fetch(`${this.baseURL}${endpoint}`, { 29 method: \u0026#39;GET\u0026#39;, 30 headers: this.headers, 31 }); 32 33 if (!response.ok) { 34 throw new Error(`HTTP error! status: ${response.status}`); 35 } 36 37 return response.json(); 38 } 39 40 async post\u0026lt;T\u0026gt;(endpoint: string, data: any): Promise\u0026lt;ApiResponse\u0026lt;T\u0026gt;\u0026gt; { 41 const response = await fetch(`${this.baseURL}${endpoint}`, { 42 method: \u0026#39;POST\u0026#39;, 43 headers: this.headers, 44 body: JSON.stringify(data), 45 }); 46 47 return response.json(); 48 } 49} 50 51const client = new ApiClient(\u0026#39;https://api.example.com\u0026#39;, \u0026#39;your-api-key\u0026#39;); 52 53async function getUsers(): Promise\u0026lt;User[]\u0026gt; { 54 try { 55 const response = await client.get\u0026lt;User[]\u0026gt;(\u0026#39;/users\u0026#39;); 56 return response.data; 57 } catch (error) { 58 console.error(\u0026#39;Error fetching users:\u0026#39;, error); 59 return []; 60 } 61} Click to expand and view more Plain Text Codeblock PLAINTEXT 行号 Collapse Copy This is a plain text codeblock. It should not have syntax highlighting. You can test the copy functionality here. function test() { console.log(\u0026#34;This is a test.\u0026#34;); } Click to expand and view more Inline Code This is an inline code example：const x = 42; and npm install and git commit -m \u0026quot;update\u0026quot;.\n","title":"Code Highlighting Test"},{"link":"/posts/markdown-syntax-test-document/","text":"Heading 1 This is a paragraph under a level 1 heading.\nHeading 2 This is a paragraph under a level 2 heading.\nHeading 3 This is a paragraph under a level 3 heading.\nHeading 4 This is a paragraph under a level 4 heading.\nHeading 5 This is a paragraph under a level 5 heading.\nHeading 6 This is a paragraph under a level 6 heading.\nParagraphs and Text Formatting This is a normal paragraph. It can contain bold text, italic text, bold italic text, strikethrough, inline code, and link text.\nThis is another paragraph to test spacing between paragraphs.\nBlockquotes This is a simple blockquote.\nBlockquotes can contain multiple paragraphs.\nThis is an example of a nested blockquote:\nThis is nested quote content.\nMultiple levels of nesting are possible.\nLists Unordered List First item Second item Nested item 1 Nested item 2 Even deeper nested item Third item Ordered List First item Second item Nested ordered item 1 Nested ordered item 2 Even deeper nested item Third item Task List (Checkbox) Completed task Incomplete task Another completed task Nested task list Subtask 1 (done) Subtask 2 (not done) Subtask 3 (done) Definition List Term 1 This is the definition for term 1. Term 2 This is the definition for term 2. Terms can have multiple definitions. Code Inline Code This is a paragraph with console.log('Hello World') inside.\nCode Blocks JAVASCRIPT 行号 Collapse Copy 1function greet(name) { 2 console.log(`Hello, ${name}!`); 3} 4 5greet(\u0026#39;World\u0026#39;); Click to expand and view more PYTHON 行号 Collapse Copy 1def fibonacci(n): 2 if n \u0026lt;= 1: 3 return n 4 return fibonacci(n-1) + fibonacci(n-2) 5 6print(fibonacci(10)) Click to expand and view more CSS 行号 Collapse Copy 1.prose { 2 max-width: none; 3 color: var(--tw-prose-body); 4} 5 6.prose h1 { 7 font-size: 2.25rem; 8 font-weight: 700; 9} Click to expand and view more Tables Left Align Center Align Right Align Content 1 Content 2 Content 3 Longer content Medium Short Data A Data B Data C Horizontal Rule Images Sample Image Links This is a regular link.\nThis is a link with title.\nThis is a reference-style link: Reference Link\nFootnotes This is a paragraph with a footnote1.\nHere is another footnote2.\nHighlighted Text This is a paragraph with ==highlighted text==.\nSuperscript and Subscript H2O is the chemical formula for water.\nE = mc^2^ is Einstein\u0026rsquo;s mass-energy equation.\nKeyboard Keys Press Ctrl + C to copy text.\nAbbreviations HTML is the abbreviation for HyperText Markup Language.\n*[HTML]: HyperText Markup Language\nMath Formula (if KaTeX supported) Inline formula: $E = mc^2$\nBlock formula:\n$$ \\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi} $$\nAdmonitions (if supported) Note This is a note.\nTip This is a tip.\nImportant This is important information.\nWarning This is a warning.\nCaution This is a caution.\nDetails (if supported) Click to expand details This is the collapsed detailed content.\nYou can include any Markdown syntax here:\nList item Bold text Code Mixed Content Test This paragraph contains multiple formats: bold, italic, code, link, strikethrough, ==highlight==.\nComplex List First item with bold text Nested item with code Another nested item with link Second item with italic text Ordered nested item Another ordered nested item Third item with strikethrough text Complex Table Feature Status Description Bold ✅ Supports bold text Italic ✅ Supports italic Code ✅ Supports inline code Link ✅ Supports links Strikethrough ❌ Needs testing This test document covers most common Markdown syntax and can be used to verify the completeness and aesthetics of prose styles.\nThis is the content of the first footnote.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis is the content of a named footnote.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","title":"Markdown Syntax Test Document"}],"tags":[{"link":"/tags/alert/","name":"Alert","slug":"Alert"},{"link":"/tags/code/","name":"Code","slug":"Code"},{"link":"/tags/image/","name":"Image","slug":"Image"},{"link":"/tags/markdown/","name":"Markdown","slug":"Markdown"},{"link":"/tags/prose/","name":"Prose","slug":"Prose"},{"link":"/tags/rendering/","name":"Rendering","slug":"Rendering"},{"link":"/tags/style/","name":"Style","slug":"Style"},{"link":"/tags/syntax-highlighting/","name":"Syntax-Highlighting","slug":"Syntax-Highlighting"},{"link":"/tags/test/","name":"Test","slug":"Test"},{"link":"/tags/%E5%8A%9F%E8%83%BD/","name":"功能","slug":"功能"},{"link":"/tags/%E5%AF%BC%E8%88%AA%E6%A0%8F/","name":"导航栏","slug":"导航栏"},{"link":"/tags/%E6%B5%8B%E8%AF%95/","name":"测试","slug":"测试"}]}