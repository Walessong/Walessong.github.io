---
title: "深度复盘：从「工程暴力」到 Context Engineering，如何在 AI 时代重塑个人产出"
date: 2026-02-22
draft: false
series: ["Tech & Engineering"]
---

## 一、认知重塑：飞机的诞生不需要羽毛

过去几年，学术界与工程界对 AI 的发展有着截然不同的视角。杨立昆指出了 LLM 的致命缺陷：缺乏物理世界理解、没有持久记忆、本质只是「预测下一个 Token」。

从追求「真正智慧」的学术角度看，他是对的。但工程学的美妙之处在于：解决问题不需要追求「本质的优雅」。工程界用两招直接绕过了这座大山：

1. **资本的暴力美学**：用极其庞大的算力堆叠出「涌现」能力，大力出奇迹。
2. **系统性的外挂补丁**：没有记忆？接向量数据库（RAG）；看不懂物理世界？接 Vision 和外部工具。

**我的思考**：不要陷入「它到底算不算真正智能」的哲学探讨。飞机没有羽毛也不会拍打翅膀，但它飞得比鸟更高更远。在使用 AI 时，我们应该具有「工程师思维」——关注它能做到什么，用外挂和补丁去弥补它的短板，而不是苛求它完美。

---

## 二、直面缺陷：那个每次醒来都失忆的天才

虽然外挂能解决很多问题，但「绕过去」不等于「真解决」。只要底层的 LLM 架构不变，AI 永远是一个没有原生记忆、每次启动都重新格式化的高智商大脑。

在使用多 Agent 协作（如 KAI 的多个分身）时，这种「认知断裂」尤为明显。如果记忆不同步，哪怕表现得像同一个人，它们也是完全割裂的个体。AI 的所有理解和偏好，都只存在于你当前投喂的上下文中。

**我的思考**：放弃对 AI 产生「人类式连续记忆」的幻想。当你觉得 AI 变笨了，或者各说各话时，问题不在于模型本身，而在于你没有帮它做好「认知同步」。把 AI 当作一个需要不断重新输入前情提要的高级处理器。

---

## 三、核心竞争力转移：Context Engineering 决定产出上限

这是整盘思考中最致命的觉醒。在 AI 时代，人与人之间的学历、年资、底层硬技能（如手写代码的能力）正在被快速压缩。真正的护城河变成了：**Context Engineering（上下文工程）的精度**。

帖子里提到的 Opus 4.6 调用 GPT 5.3-Codex 的例子，是最好的实战教材：

- **平庸的用法（MCP 协议污染）**：让主模型直接处理每一个报错、读档、重试。几十个回合下来，主 Context 塞满垃圾，AI 彻底迷失，产出断崖式下跌。
- **高阶的用法（Sub-agent 隔离）**：把脏活累活交给独立的 Sub-agent 在自己的 Context 里闭门解决，最后只给主模型返回一个精简的「摘要（Handoff summary）」。

**我的思考**：同样一个模型，用法不同，产出差十倍。谁能把 Context 保持得最干净、谁知道何时该清空重来、何时该注入关键信息，谁就能最大化 AI 的效能。

---

## 🚀 给未来的自己：AI 协作的三条铁律

基于以上复盘，在未来的日常工作与投资/开发中，必须遵守以下纪律：

1. **放弃养成癖，做好状态管理**：不要期待 AI 会「自然懂你」。在开启重要任务前，先准备好清晰的 MEMORY.md 或状态文档，每次对话前手动帮 AI 进行「认知对齐」。

2. **警惕上下文污染（Context Pollution）**：把 Context Window 视为极其昂贵的「内存」。不要让中间过程的挣扎、报错和无关闲聊污染了主线任务。一旦发现 AI 开始绕圈子，立刻果断截断，总结当前进度，开新对话（New Chat）继续。

3. **拥抱「分包机制」而非「微操」**：学会系统架构设计。将复杂任务拆解，用 Sub-agent 去处理繁琐的中间步骤。主控台（Main Context）只看结果报告，不看中间过程的「屎山代码」。

---

## 总结

1. 现在 LLM 是工程端「大力出奇迹」的结果，底层模型存在缺乏逻辑与原生记忆的根本缺陷。
2. 人与人之间原本难以跨越的能力与经验差距，正在被 AI 迅速抹平。
3. 在「强大工具」变得廉价且易得的时代，如何调用与驱动 AI 的能力，已经比自身苦练多年的基础能力更具决定性。
4. 核心竞争力是 Context Engineering，当 AI 成为通用的数字义肢，胜负就在于谁能更精准地进行「上下文工程」。管理记忆、筛选信息、同步不同 session 的认知断裂，将成为未来如何用好 AI 的关键。
