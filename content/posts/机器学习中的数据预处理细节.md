---
title: "机器学习中的数据预处理细节"
date: 2025-08-17
draft: false
series: ["Tech & Engineering"]
---

机器学习预处理的"潜规则"：数据划分与缺失值处理
========================

在机器学习的实践中，我们常说"数据和特征决定了机器学习的上限，而模型和算法只是在逼近这个上限而已"。这凸显了数据预处理在整个工作流中的核心地位。然而，在预处理的众多环节中，有两个问题常常困扰着初学者，甚至是一些有经验的工程师：

1. 训练集和测试集的预处理应该如何正确执行？

2. 面对数据中的缺失值，我们应该如何科学地应对？

处理不好这两个问题，不仅可能导致模型评估结果虚高，更会使模型在真实世界的应用中表现大打折扣。今天，我们就来深入探讨这两个关键细节。

* * *

黄金法则：始终先划分，再预处理
---------------

一个常见的疑问是：我们应该将训练集和测试集合并在一起进行预处理，还是应该分开处理？

这个问题的答案可以归结为一个核心原则：**任何预处理的"学习"过程，都必须且只能在训练集上完成**。测试集的作用是模拟模型在未来会遇到的、完全未知的数据。如果在预处理阶段让训练数据"看到"了测试数据的信息（这个过程也称为"数据泄露"），那么模型的评估结果将不再可靠。

让我们将这个问题拆解为两个层面来理解：

#### 1. 预处理操作需要保持一致吗？

**需要。** 为了保证模型的一致性，训练集和测试集必须经过完全相同的预处理流程。机器学习算法通常假设训练数据和测试数据服从相似的分布。如果在两个数据集上应用了不同的预处理方法，就破坏了这个基本假设，模型将难以泛化。

#### 2. 预处理的"参数"可以混合计算吗？

**绝对不能。** 这是最关键也最容易犯错的地方。当我们进行标准化（计算均值、方差）、归一化（计算最大值、最小值）或者主成分分析（PCA）时，这些转换操作所依赖的"参数"（如均值、方差、主成分向量等）必须**仅从训练集中计算得出**。

**正确的流程应该是：**

1. **划分数据**：首先，将你的数据集划分为训练集和测试集。

2. **学习参数**：在**训练集**上进行预处理操作的"拟合"（fit），计算出所需的转换参数（例如，`StandardScaler`的均值和标准差）。

3. **应用转换**：使用上一步学习到的参数，分别对**训练集**和**测试集**进行转换（transform）。

**为什么不能混合计算？**

想象一下，在真实的工业应用中，新数据是逐个或分批次到来的。你不可能每次来一个新样本，就把所有历史数据和新数据放在一起重新计算均值和方差，再重新训练模型。正确的做法是，用已经部署好的、基于原始训练数据训练的模型和预处理流程来直接处理新数据。因此，在训练阶段就必须严格遵守这一原则。

有人可能会说，"把训练集和测试集一起归一化可以提高模型效果"。这是一个典型的伪命题。这种操作带来的"效果提升"仅仅是在这个特定的、被信息污染的测试集上的虚假表现。模型真正的价值在于它对未来未知数据的预测能力，而这种作弊行为恰恰破坏了我们对这种能力的准确评估。

> **一个例外**：当你已经完成了模型的训练和评估，并准备将其部署为最终产品时，可以把训练集和测试集重新组合成一个更大的数据集，使用之前验证过的最佳模型参数和预处理流程，对全部数据进行重新训练。这样做是为了最大化地利用所有可用数据，以期获得一个更鲁棒的最终模型。

* * *

策略性填补：如何优雅地处理缺失值
----------------

数据缺失是现实世界中不可避免的问题。对于如何处理缺失值，业界没有一成不变的"标准答案"，但我们可以根据项目的目标来制定合理的策略。这里我们主要讨论数据是随机缺失的情况。

一个常见的说法是，缺失率在20%以内的变量可以考虑填补，但具体情况还需具体分析，核心在于区分研究的目标是**因果推断**还是**预测建模**。

#### 1. 面向因果推断的研究

因果推断旨在分析变量间的因果关系，对数据的真实性和完整性要求极高。因此，对缺失值的容忍度较低。

* **使用简单填补法**：如果你计划使用均值、中位数或末次观测值结转（LOCF）等机械填补方法，建议变量的缺失率控制在 **10%** 以内。因为这些方法会扭曲数据的原始分布，较高的缺失率会引入显著的偏倚。

* **使用高级填补法**：如果采用多重填补（Multiple Imputation）等利用数据间关联性进行填补的策略，可以将缺失率的容忍度放宽到 **20%** 左右。

#### 2. 面向预测模型的研究

与因果推断不同，预测建模的核心目标是构建一个在内部和外部数据上都表现一致、预测能力强的模型。它更关注结果的准确性和稳健性，而非变量间的因果解释。

在这种场景下，我们对缺失值的容忍度可以更高。只要你的填补策略能帮助建立一个在外部验证中表现良好的模型，那么这个策略就是合理的。**预测模型的最终裁判是外部验证的结果**。

* **缺失率上限**：对于预测模型，缺失率在 **30%** 以内的变量通常都可以尝试保留和填补。

* **验证是关键**：关键在于，填补后建立的模型必须经过严格的验证。最理想的是使用一个独立的外部数据集进行验证。如果没有，也可以将原始数据中的完整病例作为验证集，来检验模型的稳健性。

说得极端一点，如果你的模型（哪怕数据是模拟生成的）能够在外部验证中持续获得优异且一致的结果，那么你的数据处理方式就是成功的。当然，缺失比例过高的数据在填补后容易失真，这样的模型通常很难通过严格的验证性分析。
